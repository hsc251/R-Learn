---
title: "Tidyverse_Model"
author: "Hsin Chih Chen"
date: "12/29/2021"
output: html_document
---

## Preliminary Setup

This code chunk illustrates the library and file loading setup before executing data inspection and machine learning progress.

Since the URL varies for the access, so the csv were pre-downloaded

```{r Setup, include = FALSE}
# Read Library
library(tidyverse) # to manipulate df
library(tidymodels) # for machine learning build up
library(tm) # to manipulate text
library(parallel) # to speed up the processing

# Read csv files
df <- read_csv("data_complaints_train.csv")

# Rename complain column for easier access and transit product categories as a factor
df <- df %>%
  rename(Complains = `Consumer complaint narrative`)

# Change display for the number view correction
options(scipen = 100)
```

Let's look at the complain category distribution before filtering the data.

```{r Pre-Filter Count}
ggplot(df, aes(x = Product, fill = Product))+
  geom_bar() +
  labs(x = "Product Category", y = "Count", title = "Claim Category Summary") +
  theme(legend.position = "none")  
```

## Data Structure Inspection
```{r Inspect Data 1, warning = FALSE}
# Check general data structure of data frame
glimpse(df)
```

```{r Inspect Data 2, warning = FALSE}
# Check categories within the product
unique(df$Product)
```

```{r Inspect Data 3, warning = FALSE}
# Inspect the header rows of complains
head(df$Complains)
```

Based on the inspection of raw data frame, only 4 categories are available for considering the complains as factor. But data wrangling is required for the cleaning of data.

## Data Wrangling

For the data description, the following items shall be executed to wrangle data.

  1. Drop any NA rows in the column
  2. Remove any strings such as "XX", "XXX" and "XXXX" which were used to mask private information.
  3. Convert to all lower cases.
  4. Remove any numbers.
  5. Remove all punctuation.
  6. Remove escape characters and white spaces
  7. Remove stop words such as "I", "My", "which", "won't"....etc.
  
```{R Data Wrangle}
dfc <-df %>%
    filter(Complains!=is.na(.)) %>%
    mutate(Complains=gsub("[XX]+", "", Complains)) %>%
    mutate(Complains=str_to_lower(Complains)) %>%
    mutate(Complains=gsub("[0-9]", "", Complains)) %>%
    mutate(Complains=removePunctuation(Complains)) %>%
    mutate(Complains=gsub("\n", "", Complains)) %>%
    mutate(Complains=gsub("\t", "", Complains)) %>%
    mutate(Complains=stripWhitespace(Complains))
```

```{R Clean Complains, warning = FALSE}
Complain<-Corpus(VectorSource(dfc$Complains)) %>%
    tm_map(removeWords, stopwords())
```

After data cleaning, document term matrix using `tm` package to classify each complaint as a document occupying a row while each term will have its column name and where as counts of each term per document will be the numeric values.

```{R Document Term Matrix}
dtm_c <- DocumentTermMatrix(Complain)

inspect(dtm_c)
```

Based on the preliminary analysis, there are `90975` documents and `81653` terms. The numbers shall be reduced to maintain relevant terms for detailed analysis. So filtering is required to ensure relevant terms which appears 1000 times or more.

```{R Document Trimming}
commonTerm <- findFreqTerms(dtm_c, lowfreq = 1000)

dtm_c <- DocumentTermMatrix(Complain, list(dictionary = commonTerm))

inspect(dtm_c)
```

After trimming down the document, `1552` terms were remaining. But the sparsity has dropped marginally to 96%. Then the terms shall be initiated to trim more.

```{R Sparse Removal}
dtm_c <- removeSparseTerms(dtm_c, 0.95)
inspect(dtm_c)
```

```{R Extra Wrangle, warning = FALSE}
extraStops<-c("told", "called", "back", "get", "will", "never", "said", "can", "call", "now", "also",
"even", "just", "like", "please", "take", "want", "going", "without", "got", "however",
"went", "able", "didnt", "dont", "put", "later", "way", "done", "needed", "today", "used", "took")

Complain <- tm_map(Complain, removeWords, extraStops)
```

```{R DTM Re-Run}
dtm_c <- DocumentTermMatrix(Complain, list(dictionary = commonTerm))
dtm_c <- removeSparseTerms(dtm_c, 0.95)
inspect(dtm_c)
```

By the additional stop word filters, the remaining terms quantity is `308`.

## Machine Learning Data Setup

After place the cleaned train data as `dtm_c`, now it's time to execute the machine learning setup. The data set will be split into train set(75%) and test sets (25%).

```{R ML Dataset Setup}
# Convert the document term matrix as a data frame while add the product column from original data.
dfc <- dfc %>%
  mutate(Product = factor(Product))

dtm_cm <- as.matrix(dtm_c)
dtm_tr <- dtm_cm %>%
  as.matrix()%>%
  as.data.frame() %>%
  bind_cols(Product = dfc$Product) %>%
  select(Product, everything())

# Create train dataset
set.seed(369)
dtm_split <- initial_split(dtm_tr, strata = Product, prop = 3/4)
dtm_training <- training(dtm_split)
dtm_testing <- testing(dtm_split)
```

Then View the Structure of respective dataset
```{R ML Training Set View}
head(dtm_training)
```

```{R ML Test Set View}
head(dtm_testing)
```

```{R ML Training Set Counts}
count(dtm_training, Product)
```

```{R ML Test Set Counts}
count(dtm_testing, Product)
```

## Cross Validation Fold Setup

Before execute the machine learning process, cross validation folds need to be generated with `rsample` for the fold cross validation (in this case 10)

```{R Cross-Validation Fold}
dtm_vfold <- vfold_cv(data = dtm_training, v=10)

dtm_vfold
```

```{R Pull Fold}
pull(dtm_vfold, splits)
```

```{R 1st Fold Extraction}
# Select first fold for verification
dtm_vfold_first <- dtm_vfold$splits[[1]]

# Training set for this fold
head(as.data.frame(dtm_vfold_first, data = "analysis"))

# Test set for this fold
head(as.data.frame(dtm_vfold_first, data = "assessment"))
```

## Machine Learning Workflow Generation

Creation of recipe, model and workflow for machine learning can be initiated after preliminary information is gathered, now classification can be executed.

```{R ML Model Generation, message = FALSE}
# Recipe creation
dtm_recipe <- dtm_training %>%
  recipe(Product~.)

# Model creation
dtm_model <- decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart")

dtm_model
```

```{R ML Workflow Generation, message = FALSE}
dtm_work <- workflow() %>%
  add_recipe(dtm_recipe) %>%
  add_model(dtm_model)

dtm_work
```

## Model Fit Assessment Check

After required workflow and data are initialized, it's time to fit in the data for the accuracy check.

```{R Initial Fit W/O Cross Validation, message = FALSE, warning = FALSE}
dtm_fit1 <- fit(dtm_work, data = dtm_training)
dtm_fit1_work <- dtm_fit1 %>%
  pull_workflow_fit()
dtm_fit1_work
```

Now after the model is generated, let's verify the critical elements in the document terms
``` {R Initial Fit Variable}
dtm_fit1_work$fit$variable.importance
```

Based on the observation, the top 3 terms are `mortgage`, `card` and `loan` to predict the products. Prediction can be executed based on that.

```{R Initial Prediction}
# generate prediction results coming from training dataset
product_predict <- predict(dtm_fit1_work, new_data = dtm_training)

# validate accuracy for the prediction.
accuracy(dtm_training, truth = Product, estimate = product_predict$.pred_class)
```

The prediction results showed that `84.3%` accuracy based on the training data and prediction model. Now let's breakdown the actual data compared with the predicted results.

```{R Predict Count Comparison}
# Original Training Dataset
count(dtm_training, Product)

# Predicted Dataset
count(product_predict, .pred_class)
```

```{R Predict vs Truth}
predicted_vs_truth <- bind_cols(dtm_training, predicted_Product = pull(product_predict, .pred_class)) %>%
    select(predicted_Product, everything())

head(predicted_vs_truth)
```

Based on the initial analysis, `84.3%` accuracy was solid. Although `credit card or prepaid card` and `Mortgage` was over predicted. Meanwhile, the validation shall be re-considered to verify.

```{R Fit Model With Cross-Fold, warning = FALSE}
set.seed(469)
dtm_resample_fit <- fit_resamples(dtm_work, dtm_vfold)
collect_metrics(dtm_resample_fit)
```

## Model Finetune

This section will emphasize on tuning the hyperparameter for model's optimization

```{R Establish Tuned Model}
# Create tuned model
dtm_tuned <- decision_tree(cost_complexity = tune(), tree_depth=tune()) %>%
  set_mode("classification") %>%
  set_engine("rpart")

grid_tree <- grid_regular(cost_complexity(), tree_depth(), levels = 3)

# Create fine tuned workflow
dtm_worktune <- workflow() %>%
  add_recipe(dtm_recipe) %>%
  add_model(dtm_tuned)
```

```{R Revised Fit Setup, warning = FALSE}
# Use multiple cores for faster run time
doParallel::registerDoParallel(cores = 1)

# Perform tuning
set.seed(269)
dtm_fit2 <- tune_grid(dtm_worktune,
                      resamples = dtm_vfold,
                      grid = grid_tree,
                      metrics = metric_set(accuracy,roc_auc))
```

```{R Tuned Performance Assessment}
show_best(dtm_fit2, metric = "accuracy")
```

The highest accuracy has been improved to `88.2%`, stp the model and update the tuned workflow with chosen values via `select_best()`.  
```{R Optimize Input}
# Specify min_n value
value_tuned <- select_best(dtm_fit2, "accuracy")

# Finalize model/workflow
dtm_worktune <- dtm_worktune %>%
  finalize_workflow(value_tuned)
```

## Final Model Evaluation

Use the finalized model on the full training set via `last_fit()` function.

```{R Final Fit Setup}
final_fit <- last_fit(dtm_worktune, dtm_split)

collect_metrics(final_fit)
```

```{R Final Prediction Setup}
# Test Prediction Data
final_pred <- collect_prediction(final_fit)
head(final_pred)

# Plot product distribution
ggplot(final_pred, aes(x = Product, fill = .pred_class)) +
  geom_bar(position = "fill", color = "#666666") +
  scale_fill_brewer(palette = "Set6") +
  labs(x = "Actual Products",
       y = "Proportion",
       fill = "Predicted Outcome",
       title = "Model Prediction Distribution") +
  theme_bw()+
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust =1))
```

## Final Test Data Prediction

```{R Test Data Setup }
dft <- read_("data_complaints_test.csv") %>%
    rename(Complains = `Consumer complaint narative`) %>%
    select(Complains) %>%
    mutate(Complains=gsub("[XX]+", "", Complains)) %>%
    mutate(Complains=str_to_lower(Complains)) %>%
    mutate(Complains=gsub("[0-9]", "", Complains)) %>%
    mutate(Complains=removePunctuation(Complains)) %>%
    mutate(Complains=gsub("\n", "", Complains)) %>%
    mutate(Complains=gsub("\t", "", Complains)) %>%
    mutate(Complains=stripWhitespace(Complains))
```

```{R Test Data Corpus, warning = FALSE}
complain_test <- Corpus(VectorSource(dft$Complains)) %>%
  tm_map(removeWords, stopwords())
```

```{R Test Data DTM Setup}
# Make DTM Test
dtm_t <- DocumentTermMatrix(complain_test,list(dictionary = commonTerm))

# Convert the dtm as a matrix
dtm_tm <- dtm_t %>%
  as.matrix() %>%
  as.data.frame()
```

```{R Test Data Predictions}
model_f <- fit(dtm_worktune, dtm_train)
predict(model_f, newdata = dtm_tm)
```
