## R Programming Week 2's Programming Assignment 1

For this first programming assignment you will write three functions that are meant to interact with dataset that accompanies this assignment. The dataset is contained in a zip file **specdata.zip** that you can download from the Coursera web site. </br>

Although this is a programming assignment, you will be assessed using a separate quiz. </br>

The zip file containing the data can be downloaded here:[specdata.zip](https://d396qusza40orc.cloudfront.net/rprog%2Fdata%2Fspecdata.zip) [2.4MB] </br>

Description: The zip file contains 332 comma-separated-value (CSV) files containing pollution monitoring data for fine particulate matter (PM) air pollution at 332 locations in the United States. Each file contains data from a single monitor and the ID number for each monitor is contained in the file name. For example, data for monitor 169 is contained in the file "169.csv". Each file contains three variables: </br>

* Date: The date of the observation in YYYY-MM-DD (year-month-day)</br>
* sulfate: the level of sulfate PM in the air on that date (measured in micrograms per cubic meter)
* nitrate: the level of nitrate PM in the air on that date (measured in micrograms per cubic meter)

### Part 1 ([pollutantmean.R])

```R
pollutantmean <- function(directory,pollutant,id=1:332){

# generate the loading of file list by list.files while have directory input and put full.names = TRUE to obtain the specdata's csv files.
  files_list <- list.files(directory, full.names = TRUE)

# generate empty data frame for the data storage.
  dat <- data.frame() #empty data frame

# Generate the for loop while consider the input for the sensor ID to bind the data)
  for (i in id){
    dat <- rbind(dat, read.csv(files_list[i]))
  }

# use if and else if condition to calculate the averages for sulfate or nitrate averages
  if (pollutant == "sulfate")
  {
    sulf <-dat[, "sulfate"] 
    sulf_mean <- mean(sulf,na.rm = TRUE)
    print (sulf_mean)
  }
    
  else if (pollutant == "nitrate")
  {
    nitr <- dat [,"nitrate"]
    nitr_mean <- mean(nitr,na.rm = TRUE)
    print (nitr_mean)
  }
}

# Example usage
## If we want to analyze the nitrate concentration data from sensor 70 to sensor 72, use the following code for output.
source("pollutantmeanA.R")
pollutantmean('specdata','nitrate', 70:72)

#Solution
[1] 1.706047

```
### Part 1 Alternate Solution 

```R
pollutantmeanA <- function(directory, pollutant, id = 1:332){
  
  # Format number with fixed width and cover .csv to numbers accordingly
  filez <- paste0(directory, '/', formatC(id, width=3, flag="0"),".csv")

  # Read in all files with fast read and combine as a large data table 
  # by rbindlist to compile the list
  lst <- lapply(filez, data.table::fread)
  tbl <- rbindlist(lst)  
  
  # use the if condition to filter sulfate or nitrate and use return
  # and lapply for combining data table. And usage of .SD and .SDcols
  # for subsetting the data according by the conditions while na.rm
  # is applied to remove the NA values in the data.
  
  if(c(pollutant) %in% names(tbl)){
    return(tbl[, lapply(.SD, mean, na.rm = TRUE), .SDcols = pollutant][[1]])
  }
}

# Example usage
source("pollutantmeanA.R")
pollutantmean("specdata", "sulfate", 1:10)

#Solution
[1] 4.064128
```

### Part 2 ([complete.R](https://github.com/mGalarnyk/datasciencecoursera/blob/master/2_R_Programming/projects/complete.R))
```R
complete <- function(directory,  id = 1:332) {
  
  # Format number with fixed width and then append .csv to number
  fileNames <- paste0(directory, '/', formatC(id, width=3, flag="0"), ".csv" )
  
  # Reading in all files and making a large data.table
  lst <- lapply(fileNames, data.table::fread)
  dt <- rbindlist(lst)
  
  return(dt[complete.cases(dt), .(nobs = .N), by = ID])
  
}

#Example usage
complete(directory = '~/Desktop/specdata', id = 20:30)
```

### Part 2 Alternate Solution
```R
complete <- function(directory, id= 1:332){
  
  ## Create an empty vector of id's
  ids = c()
  
  ## Create an empty vector of nobs
  nobss = c()
  
  ## Get a list of filenames
  filenames = list.files(directory)
  
  ## For each .csv file in id
  for(i in id){
    
    ## Concatinate the directory and filename
    ## e.g. directory = "C:/folder", filenames = vector("001.csv", "002.csv", ...), filepath="C:/folder/001.csv"
    filepath=paste(directory,"/" ,filenames[i], sep="")
    
    ## read in each file and store it in data
    data = read.csv(filepath, header = TRUE)
    
    ##Get a subset of all rows with complete data meaning no NA's
    ##completeCases = subset(data, !is.na(Date) & !is.na(sulfate) & !is.na(nitrate) & !is.na(id),select = TRUE )
    completeCases = data[complete.cases(data), ]
    
    ids =  c(ids, i)                    ## We can use i for id and concatinate a vector of id's
    nobss = c(nobss, nrow(completeCases) )## Concatinates the number of completed rows from the subset into a vector
   
  }
  ## Return the data frame
  data.frame(id=ids, nobs=nobss)
}

#Example usage
source("complete.R")
complete("specdata", c(2, 4, 8, 10, 12))

#Solution
   id nobs
 1  2 1041
 2  4  474
 3  8  192
 4 10  148
 5 12   96
```

### Part 3 ([corr.R](https://github.com/mGalarnyk/datasciencecoursera/blob/master/2_R_Programming/projects/corr.R))
```R
corr <- function(directory, threshold = 0) {
  
  # Reading in all files and making a large data.table
  lst <- lapply(file.path(directory, list.files(path = directory, pattern="*.csv")), data.table::fread)
  dt <- rbindlist(lst)
  
  # Only keep completely observed cases
  dt <- dt[complete.cases(dt),]
  
  # Apply threshold
  dt <- dt[, .(nobs = .N, corr = cor(x = sulfate, y = nitrate)), by = ID][nobs > threshold]
  return(dt[, corr])
}

# Example Usage
corr(directory = '~/Desktop/specdata', threshold = 150)
```

### Part 3 Alternate Solution
```R

source("complete.R")
corr <- function(directory, threshold = 0){
  
  completes = complete(directory, 1:332)
  completes_above_threshold = subset(completes, nobs > threshold )
  
  ## Initialize empty vector variable
  correlations <- vector()
  
  ## Get a list of filenames
  filenames = list.files(directory)
  
  ## For each .csv file in id
  for(i in completes_above_threshold$id){
    
    ## Concatinate the directory and filename
    ## e.g. directory = "C:/folder", filenames = vector("001.csv", "002.csv", ...), filepath="C:/folder/001.csv"
    filepath=paste(directory,"/" ,filenames[i], sep="")
    
    ## read in each file and store it in data
    data = read.csv(filepath, header = TRUE)
    
    ## Calculate and store the number of completed cases
    completeCases = data[complete.cases(data),]
    count = nrow(completeCases)
    
    ## Calculate and store the count of complete cases
    ## if threshhold is reached
    if( count >= threshold ) {
      correlations = c(correlations, cor(completeCases$nitrate, completeCases$sulfate) )
    }
  }
  correlations
}
# Example Usage
source("corr.R")
source("complete.R")
cr <- corr("specdata", 150)
head(cr)

#Solution
[1] -0.01895754 -0.14051254 -0.04389737 -0.06815956 -0.12350667 -0.07588814
```
